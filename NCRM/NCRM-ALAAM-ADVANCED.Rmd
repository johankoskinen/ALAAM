---
title: "Tutorial on ADVANCED ALAAM - NCRM"
author: "[Johan Koskinen](https://https://www.su.se/english/profiles/kosk-1.615440)"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
editor_options: 
  markdown: 
    wrap: 72
bibliography: references.bib
---
```{r, include = FALSE}
xfun::download_file("https://raw.githubusercontent.com/johankoskinen/CHDH-SNA/main/Markdowns/references.bib")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This tutorial introduces *more advanced* aspects of the Bayesian estimation for auto-logistic actor attribute models (ALAAMs)(@robins2001network, @daraganovaThesis, and @daraganova2013autologistic) developed in @koskinen2020bayesian. 

The workshop will go through

1. Data missing at random
2. Data missing not at random
3. More contagion effects
4. Interacting contagion with other effects
5. Specifying "informative" prior distributions

## Preamble for ALAAM

Load the main functions of `balaam' from GitHub and load network packages.

```{r}
source("https://raw.githubusercontent.com/johankoskinen/ALAAM/main/balaam.R")
require(sna)
require(network)
```



and don't forget to consult the (proto-) manual is avaialble on GitHub [alaam_effects](https://github.com/johankoskinen/ALAAM/blob/main/alaam_effects.pdf).

## Load and format data

WThe s50 dataset

```{r}
temp <- tempfile()
download.file("https://www.stats.ox.ac.uk/~snijders/siena/s50_data.zip",temp)
adj <- as.matrix( read.table(unz(temp, "s50-network1.dat")) )
sport <- read.table(unz(temp, "s50-sport.dat"))
smoke <- read.table(unz(temp, "s50-smoke.dat"))
alcohol <- read.table(unz(temp, "s50-alcohol.dat"))
unlink(temp)
```

format 

```{r symmetrise}
n <- nrow(adj)
adj <- as.matrix(adj) # convert from data.frame to matrix
smoke <- smoke[,2] # use wave 2
smoke[smoke<2] <- 0 # set non-smoker to 0
smoke[smoke>0] <- 1 # set occasional and regular to 1
sport <- sport-1
my.data <- data.frame(smoke=smoke, alcohol=alcohol[,1],sport=sport[,1])
```


# MAR data

The ALAAM routine automatically handles missing data in the dependent variable. Set smoking to missing for a the first five individuals

```{r}
true.vals <- my.data$smoke[1:5] 
my.data$smoke[1:5] <- NA
table(my.data$smoke, useNA='always')
```

Assuming that data are missing at random (MAR), 

```{r}
res.MAR.0 <- estimate.alaam(smoke ~odegree+alcohol+sport+simple,
                            my.data, adjacency=adj,
                           Iterations=1000,
                           missFreq = 500)
```
The output to screen that says for example imputed ones:  2  out of  5, tells us how many of the 5 missing values in that iteration that have been imputed with a 1.

> With 10% or responses missing we see some attenuation of effects (standard deviations increase)

### Check imputations

The imputed values are stored in `res.MAR.0$imputed.obs`, and here we can compare the imputed values with the true values

```{r}
table(rowMeans(res.MAR.0$imputed.obs[1:5,]),true.vals)
```


## GOF with missing

In the ordinary GOF the observed statistics are compared with the simulated statistics. When we have missing data, we do not have one value for each statistic, but a range of values.

```{r}
sim.2.na <- get.gof.distribution(NumIterations=500, # number of vectors to draw
                                  res=res.MAR.0, # the ALAAM estimation object that contains model and results
                                  burnin=100, # no. iterations discarded from GOF distribution
                                  thinning = 1000, # no. iterations between sample points
                                  contagion ='simple') #
```

When calculating the statistics, we need to add the argument `Imp.gof`

```{r}
gof.table(obs.stats=    sim.2.na$stats, # observed statistics included  not fitted statistics
          sim.stats=    sim.2.na$Sav.gof, # simulated goodness-of-fit statistics
          name.vec= sim.2.na$gof.stats.names, # names of statistics calculate, not all will be used if undirected
          tabname='ALAAMGofalt', # name of file saved
          pvalues=TRUE, # posterior predictive p-values
          save.tab ='csv', # save a csv file or a LaTex file
          Imp.gof = sim.2.na$Imp.gof)
```

### Plot goodness of fit with missing
We can compare the statistics for the predictive distribution under the fitted model, with the imputed or complemented datasets. Look at the statistic for ‘indirect contagion’

```{r}
boxplot(sim.2.na$Sav.gof[4,],sim.2.na$Imp.gof[4,],names = c('GOF','observed'), main='GOF for indirect contagion')
```

### Posterior deviance

With missing data, the likelihood is marginalised with respect to the missing entries when calculating the posterior deviance.

```{r, eval=FALSE}
# Bug prevents this from runnig
my.dev.post.MAR <- post.deviance.alaam(res.MAR.0,# the estimation object
                                  numBridges=5,# the safer default is 20
                                  thinning.like = 1000,# thinning in drawing y; should be higher
                                  sample.size = 20,# number of y drawn for each bridge
                                  cov.sample.burnin = NULL,
                                  printFreq=10,# print to screen after done 10
                                  mult.fact = 30,# depreciated
                                  num.outs=100)# number of devaiance evaluations to return
```

# MNAR data

We can never infer whether data are MAR or MNAR. We can, however, estimate them model under different assumptions for a MNAR process. In `balaam`, we can specify a bias in the missingness mechanism. Letting $D_i$ be an indicator whether the variable $Y_i$ is missing or not, then, independently for each node $i=1,\ldots,n$, the model
$$
{\rm{logit}}[\Pr(D_{ij}=1 \mid \boldsymbol{y})]=\alpha+\gamma y_i
$$
implies that successes are more (less) likely to be observed when $\gamma$ is positive (negative).

```{r}
res.MNAR.0 <- estimate.alaam(smoke ~idegree+odegree+alcohol+sport+simple,
                            my.data, adjacency=adj,
                           Iterations=1000,
                           missFreq = 500,
                           missingPhi =0.5)
```

```{r}
plot(ts(res.MNAR.0$Thetas))
```

### Sensitivity analysis

If perform the analysis for a range of different values of $\gamma$, you would compare the posteriors under different MNAR assumptions. Of particular interest is to ascertain how strong the bias has to be for your conclusions to be qualitatively different compare to MAR.

# More contagion

## Reciprocal contagion

Reinstate the missing values
```{r}
my.data$smoke[1:5] <- true.vals
table(my.data$smoke, useNA='always')
```

Given that we have directed network data, we may want to investigate if there is stronger or weaker contagion across reciprocated ties. 

> For non-direct congation effects, the lower order contagion as well as any other lower-oder statistics need to be included.

Consequently we define the model

```{r}
res.DC.RC.1 <- estimate.alaam(smoke ~ odegree+alcohol+sport+simple+recipties+recip, 
                              my.data, adjacency=adj,
                           Iterations=5100,
                        par.burnin=100,# discard the first 100 iterations
                        thinning=10)# only use every 
```

> How are parameters for contagion, reciprochal contagion and reciprocal ties related?

# Interacting contagion

Assume that we hypothesis that social influence on smoking is stronger for heavy drinkers than others. We can test this hypothesis by interacting contagion with alcohol

```{r}
res.DC.ADC.1 <- estimate.alaam(smoke ~ odegree+alcohol+sport+simple+alcohol*simple, 
                              my.data, adjacency=adj,
                           Iterations=5100,
                        par.burnin=100,# discard the first 100 iterations
                        thinning=10)# only use every 
```

# Informative priors

The inference pressuposes a prior (subjective) prior distribution $\pi(\textbf{\theta})$ for parameters. The default in `estimate.alaam` is to set this prior constant (and therefore improper). There are cases where you need a proper prior distribution. For example, if you want to calculate so-called Bayes-factors. For some data and model combinations, nuisance parameters might need to be included but not desired to be estimated.

There are two types of standard prior distributions.

## Shrinkage prior

A convenient prior is
$$
\boldsymbol{\theta} \thicksim \mathcal{N}_p(\boldsymbol{\mu},\lambda I^{-1})
$$
where $\boldsymbol{\mu}$ is all zero,  except $\mu_1$ which is set to the MLE for the intercept. For variance, $\lambda>0$ is a chosen shrinkage and $I$ is an approximation to the information matrix.

The argument to `estimate.alaam` is `scalePrior`. Calling this $c$, the prior variance-covariance is set to 
$$
c\left\{\mathbb{E}_{\boldsymbol{\mu}}[\boldsymbol{z}(\boldsymbol{y})\boldsymbol{z}(\boldsymbol{y})^{\top}]-\mathbb{E}_{\boldsymbol{\mu}}[\boldsymbol{z}(\boldsymbol{y})]\mathbb{E}_{\boldsymbol{\mu}}[\boldsymbol{z}(\boldsymbol{y})]^{\top}\right\}^{-1}
$$
## Subjective prior

A suybjectively determined normal prior
$$
\boldsymbol{\theta} \thicksim \mathcal{N}_p(\boldsymbol{\mu},\boldsymbol{\Sigma})
$$
can be specified by passing the arguments `priorMu` and `priorSigma` to `estimate.alaam`.

### Example

In the last model, we have

```{r}
dim(res.DC.ADC.1$Thetas)[2]
```

parameters. We need a prior covariance matrix that is $6\times 6$, and a prior mean that is $6\times 1$. Assume that we **strongly** believ that the parameter for sport is $-1$, with a standard deviation of 1. Let us put arbitrary numbers for the variances of the other parameters. Define

```{r}
priorSigma <- diag(c(1,.2,.1,1,.0001,.01))
priorMu <- matrix(0,6,1)
```

Reestimate with additional arguments `priorSigma` and `priorMu`

```{r}
res.DC.ADC.prior.0 <- estimate.alaam(smoke ~ odegree+alcohol+sport+simple+alcohol*simple, 
                              my.data, adjacency=adj,
                           Iterations=1000,
                        par.burnin=100,# discard the first 100 iterations
                        thinning=3,# only use every 
                        prevBayes = res.DC.ADC.1,
                        priorSigma = priorSigma,
                        priorMu =priorMu)
```


```{r}
res.DC.ADC.prior.1 <- estimate.alaam(smoke ~ odegree+alcohol+sport+simple+alcohol*simple, 
                              my.data, adjacency=adj,
                           Iterations=5100,
                        par.burnin=100,# discard the first 100 iterations
                        thinning=10,# only use every 
                        prevBayes = res.DC.ADC.prior.0,
                        priorSigma = priorSigma,
                        priorMu =priorMu)
```



# Performing ALAAM where networks are imputed from ERGM

Assuming that there are missing tie-variables (and possibly other missing covariates), let's assume that we have $G$ networks $x^{[1]},\ldots,x^{[2]}$ imputed from $ERGM(\beta)$, that has been marginalised with respect to $\beta$. Let us denote the predictive distribution of the $x^{[g]}$'s by $p(x)$, then the implied posterior for $\theta$ is based on the likelihood

$$
E_x(p(y| x, \theta ))=\sum_{x}p(y| x, \theta ) p(x)
$$

When calculating the deviance, 
$$
\ell (\theta ; y) = \log \{ E_x(p(y| x, \theta )) \}
$$
We can use a Monte Carlo estimate for the expectation

$$
\hat{\ell} (\theta ; y) = \log \frac{1}{G} \sum_g \exp{\ell (\theta ; y,x^{[g] })}
$$
This quantity is straightforward to calculate by calculating the relative likelihoods for each set of imputations. The likelihoods need to be calculated for the same parameter values however. When there are missing values in the outcome $y$, imputations on the outcome are needed for the calculations.

### A simplified pooling of posterior deviances

While these are taken care of by virtue of the path sampler used to evaluate the likelihoods are simulation based, we can simplify the approach by letting $\hat{\ell} (\theta ; y) $ be based on **one** sample point, for each of the parameter values in the combined posteriors. For imputed networks $x^{[1]},\ldots,x^{[G]}$, where we denote the ALAAM likelihoods $\ell_{g} (\theta ; y) $, for $g=1,\ldots,G$, we have run $G$ ALAAM estimations, for each $g$ having posterior draws $\theta^{[1,g]},\ldots,\theta^{[K,g]}$, estimate
$$
\hat{\ell}_{rel} (\theta^{[k,g]} ; y) =\hat{\ell} (\theta^{[k,g]} ; y) - \ell_{\rm indep} (\hat{\theta } ; y)
$$

using ``r'aitkinPostDev'`` and adding the independent likelihood obtained from ``r 'independLike'``. 


> The point estimate for the independent model $\hat{\theta}$ needs to be the same across all $g=\ldots,G$


For the posterior deviance we can then base the ECDF on combining the individual deviances
$$
-2\hat{\ell} (\theta^{[1,1]} ; y),\ldots,-2\hat{\ell} (\theta^{[K,1]} ; y),\ldots,-2\hat{\ell} (\theta^{[1,G]} ; y),\ldots,-2\hat{\ell} (\theta^{[K,G]} ; y)
$$

The lielihood ``r 'likeeval.1 '`` above, used for $p_D$ needs to be based on an average likelihood however.



# References